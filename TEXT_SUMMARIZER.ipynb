{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WeLTAYLw2PJJ"
   },
   "source": [
    "# TEXT SUMMARIZATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET IS : AMAZON REWIEW AVAILABLE IN KAGGLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7019,
     "status": "ok",
     "timestamp": 1585311526750,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "_9reumVG2PJR",
    "outputId": "56dd3107-46d5-4a35-fe3d-7bc33bae5fd5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# IMPORT USEFUL LIBRARIES\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hz_RaFGM2PJb"
   },
   "outputs": [],
   "source": [
    "def softmax_over_time(x):\n",
    "    assert(K.ndim(x) > 2)\n",
    "    e = K.exp(x - K.max(x,axis=1,keepdims=True))\n",
    "    s = K.sum(e,axis=1,keepdims=True)\n",
    "    return e/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sy_8RP5l2PJk"
   },
   "outputs": [],
   "source": [
    "EPOCHS=70\n",
    "LATENT_DIM=256\n",
    "EMBEDDING_DIM=100\n",
    "BATCH_SIZE=64\n",
    "MAX_NUM_WORDS=40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rNPHe0cV2PJr"
   },
   "outputs": [],
   "source": [
    "# taking only first 50000 reviews\n",
    "data=pd.read_csv(\"./amazon-fine-food-reviews/Reviews.csv\",nrows=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QfkSVJbu2PJz"
   },
   "outputs": [],
   "source": [
    "data.columns=[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"target\",\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6006,
     "status": "ok",
     "timestamp": 1585311528316,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "a-NOncu22PJ6",
    "outputId": "99ce6741-079e-4d8c-c370-eaf7558359fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>target</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500273</td>\n",
       "      <td>B000YUOWVO</td>\n",
       "      <td>A254AOCWGTFNQG</td>\n",
       "      <td>Andrea \"Andrea\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1235260800</td>\n",
       "      <td>The Best Creamer Ever!!!</td>\n",
       "      <td>The BEST CREAMER EVER!!!!  I love this creamer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500274</td>\n",
       "      <td>B000YUOWVO</td>\n",
       "      <td>A1AH8OWVZ85YRL</td>\n",
       "      <td>Joey D. Veasey</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1270598400</td>\n",
       "      <td>Good Stuff - but PRICE IS CLIMBING</td>\n",
       "      <td>This is good stuff (some probs with the pump)&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500275</td>\n",
       "      <td>B000YUOWVO</td>\n",
       "      <td>A2UQ16KW38FILX</td>\n",
       "      <td>kelsey13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1336262400</td>\n",
       "      <td>coffee heaven</td>\n",
       "      <td>this is the stuff you can only get at gas stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500276</td>\n",
       "      <td>B000YUOWVO</td>\n",
       "      <td>A2V1K5WX0VGZI4</td>\n",
       "      <td>Noah D. Goldblatt</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1288224000</td>\n",
       "      <td>No Refrigeration Required, Full of Trans Fat!</td>\n",
       "      <td>I purchased this because I was in a dorm room ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500277</td>\n",
       "      <td>B003QNLUTI</td>\n",
       "      <td>A2EKWSI3QO8WG1</td>\n",
       "      <td>John Morgan</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1338249600</td>\n",
       "      <td>Lots of ENERGY</td>\n",
       "      <td>I Work 12 hour shifts that usually turn into 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        1           2               3                  4  5  6  7           8  \\\n",
       "0  500273  B000YUOWVO  A254AOCWGTFNQG    Andrea \"Andrea\"  0  0  5  1235260800   \n",
       "1  500274  B000YUOWVO  A1AH8OWVZ85YRL     Joey D. Veasey  1  2  2  1270598400   \n",
       "2  500275  B000YUOWVO  A2UQ16KW38FILX           kelsey13  0  1  5  1336262400   \n",
       "3  500276  B000YUOWVO  A2V1K5WX0VGZI4  Noah D. Goldblatt  2  5  1  1288224000   \n",
       "4  500277  B003QNLUTI  A2EKWSI3QO8WG1        John Morgan  1  1  5  1338249600   \n",
       "\n",
       "                                          target  \\\n",
       "0                       The Best Creamer Ever!!!   \n",
       "1             Good Stuff - but PRICE IS CLIMBING   \n",
       "2                                  coffee heaven   \n",
       "3  No Refrigeration Required, Full of Trans Fat!   \n",
       "4                                 Lots of ENERGY   \n",
       "\n",
       "                                                Text  \n",
       "0  The BEST CREAMER EVER!!!!  I love this creamer...  \n",
       "1  This is good stuff (some probs with the pump)<...  \n",
       "2  this is the stuff you can only get at gas stat...  \n",
       "3  I purchased this because I was in a dorm room ...  \n",
       "4  I Work 12 hour shifts that usually turn into 1...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uZOPUcDY2PKD"
   },
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=[\"Text\"],inplace=True)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5007,
     "status": "ok",
     "timestamp": 1585311528320,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "yIxQLNr82PKJ",
    "outputId": "cd8a00b0-9fe4-4acb-9a9a-27b1bdefba2d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45198.000000</td>\n",
       "      <td>45198.000000</td>\n",
       "      <td>45198.00000</td>\n",
       "      <td>45198.000000</td>\n",
       "      <td>4.519800e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>524667.827050</td>\n",
       "      <td>1.586398</td>\n",
       "      <td>2.05310</td>\n",
       "      <td>4.192840</td>\n",
       "      <td>1.297111e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14362.737112</td>\n",
       "      <td>5.156120</td>\n",
       "      <td>5.84521</td>\n",
       "      <td>1.302383</td>\n",
       "      <td>4.780095e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>500273.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.057104e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>512430.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.272586e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>524599.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.311638e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>537317.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.333670e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>550265.000000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>286.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.351210e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   1             5            6             7             8\n",
       "count   45198.000000  45198.000000  45198.00000  45198.000000  4.519800e+04\n",
       "mean   524667.827050      1.586398      2.05310      4.192840  1.297111e+09\n",
       "std     14362.737112      5.156120      5.84521      1.302383  4.780095e+07\n",
       "min    500273.000000      0.000000      0.00000      1.000000  1.057104e+09\n",
       "25%    512430.250000      0.000000      0.00000      4.000000  1.272586e+09\n",
       "50%    524599.500000      0.000000      1.00000      5.000000  1.311638e+09\n",
       "75%    537317.750000      2.000000      2.00000      5.000000  1.333670e+09\n",
       "max    550265.000000    281.000000    286.00000      5.000000  1.351210e+09"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HhpXvdub2PKO"
   },
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "\n",
    "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zYjRuq7s2PKW"
   },
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4-wEN4Ji2PKZ"
   },
   "outputs": [],
   "source": [
    "stopwords=set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2MO4bBl52PKe"
   },
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    new_string=text.lower()\n",
    "    new_string=BeautifulSoup(new_string,'lxml').text  # remove html tags\n",
    "    new_string = re.sub(r'\\([^)]*\\)','', new_string)\n",
    "    new_string = re.sub('\"','', new_string)    \n",
    "    new_string=\" \".join([contraction_mapping[t] if t in contraction_mapping else t for t in new_string.split(\" \")]) # contraction mapping\n",
    "    new_string= re.sub(\"[^a-zA-Z]\", \" \", new_string) # remove punctuations\n",
    "    new_string= re.sub(r\"'s/b\",\"\",new_string)\n",
    "    \n",
    "    tokens = [w for w in new_string.split() if not w in stopwords] # stopword removal\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>=3:                  #removing short word\n",
    "            long_words.append(i)   \n",
    "            \n",
    "    return (\" \".join(long_words)).strip()\n",
    "\n",
    "cleaned_text=[]\n",
    "for t in data['Text']:\n",
    "    cleaned_text.append(text_cleaner(t))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hcJrKz_Y2PKk"
   },
   "outputs": [],
   "source": [
    "def summary_cleaner(text):\n",
    "    new_string=text.lower()\n",
    "    new_string=re.sub('\"','',new_string)\n",
    "    new_string = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in new_string.split(\" \")])\n",
    "    new_string= re.sub(\"[^a-zA-Z]\", \" \", new_string) # remove punctuations\n",
    "    new_string= re.sub(r\"'s/b\",\"\",new_string)\n",
    "    tokens=new_string.split()\n",
    "    new_string=''\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                 \n",
    "            new_string=new_string+i+\" \" \n",
    "    return new_string.rstrip()\n",
    "\n",
    "cleaned_summary = []\n",
    "for t in data['target']:\n",
    "    cleaned_summary.append(summary_cleaner(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IkbTGWQ73PZS"
   },
   "outputs": [],
   "source": [
    "input_texts = cleaned_text\n",
    "target_texts = []\n",
    "target_texts_inputs=[]\n",
    "\n",
    "for sen in cleaned_summary:\n",
    "    sen1 = \"<sos>\" + sen\n",
    "    sen2 = sen + \"<eos>\"\n",
    "    target_texts.append(sen2)\n",
    "    target_texts_inputs.append(sen1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16396,
     "status": "ok",
     "timestamp": 1585311543399,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "2X3DO1xQvCHR",
    "outputId": "fc0f66d9-8813-4295-af21-dc41eb07df97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45198\n",
      "45198\n",
      "45198\n"
     ]
    }
   ],
   "source": [
    "print(len(input_texts))\n",
    "print(len(target_texts))\n",
    "print(len(target_texts_inputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aU0UYy2O2PKo"
   },
   "outputs": [],
   "source": [
    "input_texts_1=[]\n",
    "target_texts_1=[]\n",
    "target_texts_input_1=[]\n",
    "for t in range(len(input_texts)):\n",
    "    if len(target_texts[t].split()) <= 10 and len(input_texts[t].split()) <= 50  :\n",
    "        input_texts_1.append(input_texts[t])\n",
    "        target_texts_1.append(target_texts[t])\n",
    "        target_texts_input_1.append(target_texts_inputs[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16215,
     "status": "ok",
     "timestamp": 1585311544269,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "nF-h34zJAgHo",
    "outputId": "31d8d8e5-fd7c-4971-9de9-f9015c3768cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35234\n",
      "35234\n",
      "35234\n"
     ]
    }
   ],
   "source": [
    "print(len(input_texts_1))\n",
    "print(len(target_texts_1))\n",
    "print(len(target_texts_input_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15615,
     "status": "ok",
     "timestamp": 1585311544270,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "Aq890PZY2PKt",
    "outputId": "18f1ebf4-0a85-4dc9-92f9-efeb2041624c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos>lives up to its claims\n",
      "lives up to its claims<eos>\n"
     ]
    }
   ],
   "source": [
    "print(target_texts_input_1[5])\n",
    "print(target_texts_1[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BVv446DGtns7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gLsb6HOL2PK0"
   },
   "outputs": [],
   "source": [
    "# Tokenize input sentence\n",
    "NUM_OF_SAMPLES = len(input_texts_1)\n",
    "tokenizer_input = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer_input.fit_on_texts(input_texts_1)\n",
    "input_sequences = tokenizer_input.texts_to_sequences(input_texts_1)\n",
    "\n",
    "# Tokenize encoder input and output\n",
    "tokenizer_output = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer_output.fit_on_texts(target_texts_input_1+[\"<eos>\"])\n",
    "target_sequences_input = tokenizer_output.texts_to_sequences(target_texts_input_1)\n",
    "target_sequences = tokenizer_output.texts_to_sequences(target_texts_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16495,
     "status": "ok",
     "timestamp": 1585311547234,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "pkusr2cb-CBe",
    "outputId": "11a594cc-fad2-45a7-d489-a3772bebad5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35234\n"
     ]
    }
   ],
   "source": [
    "print(NUM_OF_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15707,
     "status": "ok",
     "timestamp": 1585311547238,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "03lKNR812PK6",
    "outputId": "33c54a08-051b-40bc-b0ff-d345a43a36b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 6, 1676, 32]\n",
      "[4, 6, 1676, 32, 3228]\n"
     ]
    }
   ],
   "source": [
    "print(target_sequences_input[0])\n",
    "print(target_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TgQ9NxVI2PK_"
   },
   "outputs": [],
   "source": [
    "word2idx_input=tokenizer_input.word_index\n",
    "word2idx_output=tokenizer_output.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14273,
     "status": "ok",
     "timestamp": 1585311547243,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "S9cnepM_trOX",
    "outputId": "9760708b-9b18-4b31-c6ef-81a1fb3a0664"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35234\n",
      "35234\n"
     ]
    }
   ],
   "source": [
    "word2idx_output[\"eos\"]\n",
    "print(len(target_sequences))\n",
    "print(len(target_sequences_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13627,
     "status": "ok",
     "timestamp": 1585311547245,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "2PQ-fsxu2PLH",
    "outputId": "de3289ef-af80-4f97-f15b-a26916f0831f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words:  26041\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique words: \",len(word2idx_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12892,
     "status": "ok",
     "timestamp": 1585311547247,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "Skw2YRKq2PLM",
    "outputId": "123d9966-3b8c-4864-ec5b-8eade8a19327"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "8618\n"
     ]
    }
   ],
   "source": [
    "print(word2idx_output[\"sos\"])\n",
    "num_words_output = len(word2idx_output)+1\n",
    "print(num_words_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11811,
     "status": "ok",
     "timestamp": 1585311547248,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "477Skxor2PLQ",
    "outputId": "228bccbc-d60e-4e61-8823-934b993aba6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "max_len_input=max(len(a) for a in input_sequences)\n",
    "print(max_len_input)\n",
    "# 1029 is a big values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10908,
     "status": "ok",
     "timestamp": 1585311547250,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "JCfkQzzy2PLX",
    "outputId": "d5ebc56f-7a6b-4ded-b4a8-17d2136406d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "max_len_target=max(len(a) for a in target_sequences)\n",
    "print(max_len_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MIv1wR3r2PLf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8588,
     "status": "ok",
     "timestamp": 1585311547253,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "3Z-bEteJ2PLk",
    "outputId": "9e99ad68-04b2-4c96-df95-c152dff6775b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_inputs.shape: (35234, 50)\n",
      "encoder_inputs[0]: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0   15  895   68    6  895   18\n",
      "    5   80 1854    4   72  213  615   19   13  416  115   13    2   95\n",
      "   34  335  279   18  741  895   55   13]\n"
     ]
    }
   ],
   "source": [
    "# Padding of sequences for encoder\n",
    "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
    "print(\"encoder_inputs.shape:\", encoder_inputs.shape)\n",
    "print(\"encoder_inputs[0]:\", encoder_inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5818,
     "status": "ok",
     "timestamp": 1585311547688,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "enn3Ou7N2PLo",
    "outputId": "60f26d58-cf07-4b66-9096-89414763c6db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_inputs.shape: (35234, 11)\n",
      "decoder_inputs[0]: [   1    4    6 1676   32    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# padding of sequences for decoder\n",
    "decoder_inputs = pad_sequences(target_sequences_input, maxlen=max_len_target,padding='post')\n",
    "print(\"decoder_inputs.shape:\", decoder_inputs.shape)\n",
    "print(\"decoder_inputs[0]:\", decoder_inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5164,
     "status": "ok",
     "timestamp": 1585311547690,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "K6hktCYD2PLt",
    "outputId": "d8431d9b-1a9e-4808-b1ce-432fd6609012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_targets.shape: (35234, 11)\n",
      "decoder_targets[0]: [   4    6 1676   32 3228    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# padding of sequences for decoder - Teacher forcing\n",
    "decoder_targets =pad_sequences(target_sequences,maxlen=max_len_target,padding='post')\n",
    "print(\"decoder_targets.shape:\", decoder_targets.shape)\n",
    "print(\"decoder_targets[0]:\", decoder_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5MTXvWqk2PLy"
   },
   "outputs": [],
   "source": [
    "# create embedding matrix\n",
    "word2vec = {}\n",
    "with open(\"./glove6b100dtxt/glove.6B.100d.txt\",encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values=line.split()\n",
    "        word=values[0]\n",
    "        vector=np.asarray((values[1:]),dtype='float32')\n",
    "        word2vec[word]=vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NVWE8ES92PL4"
   },
   "outputs": [],
   "source": [
    "# PREPARE EMBEDDING MATRIX\n",
    "num_words = min(MAX_NUM_WORDS,len(word2idx_input)+1)\n",
    "embedding_matrix = np.zeros((num_words,EMBEDDING_DIM))\n",
    "for word, i in word2idx_input.items():\n",
    "    if i < MAX_NUM_WORDS:\n",
    "        embedding_vector=word2vec.get(word)\n",
    "        \n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i]=embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20845,
     "status": "ok",
     "timestamp": 1585311565837,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "5z-PgL_J2PL8",
    "outputId": "223a1352-498d-480f-96a1-f3d17f4c47f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35234, 11, 8618)\n"
     ]
    }
   ],
   "source": [
    "decoder_targets_onehot=to_categorical(decoder_targets)\n",
    "print(decoder_targets_onehot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FzAUGybK2PMB"
   },
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1014,
     "status": "ok",
     "timestamp": 1585311580263,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "aMfg5DzU2PMC",
    "outputId": "8d417080-97df-4759-cfd1-d6aa91308291"
   },
   "outputs": [],
   "source": [
    "embedding_layer=Embedding(num_words,EMBEDDING_DIM,weights=[embedding_matrix],input_length=max_len_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12116,
     "status": "ok",
     "timestamp": 1585311593065,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "6WJVqEvT2PMH",
    "outputId": "ac052d76-3100-48f8-aca0-ef94826131eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 11, 8618)\n"
     ]
    }
   ],
   "source": [
    "# SETTING UP ENCODER\n",
    "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "encoder = Bidirectional(LSTM(\n",
    "  LATENT_DIM,\n",
    "  return_sequences=True,\n",
    "  dropout=0.5 # dropout not available on gpu\n",
    "))\n",
    "encoder_outputs = encoder(x)\n",
    "\n",
    "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
    "\n",
    "decoder_embedding = Embedding(num_words_output, EMBEDDING_DIM)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######### Attention #########\n",
    "# Attention layers need to be global because\n",
    "# they will be repeated Ty times at the decoder\n",
    "attn_repeat_layer = RepeatVector(max_len_input)\n",
    "attn_concat_layer = Concatenate(axis=-1)\n",
    "attn_dense1 = Dense(10, activation='tanh')\n",
    "attn_dense2 = Dense(1, activation=softmax_over_time)\n",
    "attn_dot = Dot(axes=1) # to perform the weighted sum of alpha[t] * h[t]\n",
    "\n",
    "def one_step_attention(h, st_1):\n",
    "    # h = h(1), ..., h(Tx), shape = (Tx, LATENT_DIM * 2)\n",
    "    # st_1 = s(t-1), shape = (LATENT_DIM_DECODER,)\n",
    "\n",
    "    # copy s(t-1) Tx times\n",
    "    # now shape = (Tx, LATENT_DIM_DECODER)\n",
    "    st_1 = attn_repeat_layer(st_1)\n",
    "\n",
    "    # Concatenate all h(t)'s with s(t-1)\n",
    "    # Now of shape (Tx, LATENT_DIM_DECODER + LATENT_DIM * 2)\n",
    "    x = attn_concat_layer([h, st_1])\n",
    "\n",
    "    # Neural net first layer\n",
    "    x = attn_dense1(x)\n",
    "    # Neural net second layer with special softmax over time\n",
    "    alphas = attn_dense2(x)\n",
    "\n",
    "    # \"Dot\" the alphas and the h's\n",
    "    # Remember a.dot(b) = sum over a[t] * b[t]\n",
    "    context = attn_dot([alphas, h])\n",
    "    \n",
    "\n",
    "    return context\n",
    "\n",
    "\n",
    "# define the rest of the decoder (after attention)\n",
    "decoder_lstm = LSTM(LATENT_DIM, return_state=True)\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "\n",
    "initial_s = Input(shape=(LATENT_DIM,), name='s0')\n",
    "initial_c = Input(shape=(LATENT_DIM,), name='c0')\n",
    "context_last_word_concat_layer = Concatenate(axis=2)\n",
    "\n",
    "\n",
    "\n",
    "s = initial_s\n",
    "c = initial_c\n",
    "\n",
    "# collect outputs in a list at first\n",
    "outputs = []\n",
    "for t in range(max_len_target): # Ty times\n",
    "    # get the context using attention\n",
    "    context = one_step_attention(encoder_outputs, s)\n",
    "\n",
    "    # we need a different layer for each time step\n",
    "    selector = Lambda(lambda x: x[:, t:t+1]) \n",
    "    \n",
    "    xt = selector(decoder_inputs_x)\n",
    "    # combine \n",
    "    decoder_lstm_input = context_last_word_concat_layer([context, xt])\n",
    "\n",
    "    # pass the combined [context, last word] into the LSTM\n",
    "    # along with [s, c]\n",
    "    # get the new [s, c] and output\n",
    "    o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[s, c])\n",
    "    # final dense layer to get next word prediction\n",
    "    decoder_outputs = decoder_dense(o)\n",
    "\n",
    "    outputs.append(decoder_outputs)\n",
    "\n",
    "\n",
    "# 'outputs' is now a list of length Ty\n",
    "# each element is of shape (batch size, output vocab size)\n",
    "# therefore if we simply stack all the outputs into 1 tensor\n",
    "# it would be of shape T x N x D\n",
    "# we would like it to be of shape N x T x D\n",
    "\n",
    "def stack_and_transpose(x):\n",
    "    # x is a list of length T, each element is a batch_size x output_vocab_size tensor\n",
    "    x = K.stack(x) # is now T x batch_size x output_vocab_size tensor\n",
    "    x = K.permute_dimensions(x, pattern=(1, 0, 2)) # is now batch_size x T x output_vocab_size\n",
    "    return x\n",
    "\n",
    "# make it a layer\n",
    "stacker = Lambda(stack_and_transpose)\n",
    "outputs = stacker(outputs)\n",
    "print(outputs.shape)\n",
    "\n",
    "# create the model\n",
    "model = Model(\n",
    "  inputs=[\n",
    "    encoder_inputs_placeholder,\n",
    "    decoder_inputs_placeholder,\n",
    "    initial_s, \n",
    "    initial_c,\n",
    "  ],\n",
    "  outputs=outputs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9710,
     "status": "ok",
     "timestamp": 1585311593068,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "rUZu979W2PMM",
    "outputId": "ef8f7779-12a5-4e72-ba84-65dc4ace6317"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 100)      2604200     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "s0 (InputLayer)                 [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 50, 512)      731136      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector (RepeatVector)    (None, 50, 256)      0           s0[0][0]                         \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[1][1]                     \n",
      "                                                                 lstm_1[2][1]                     \n",
      "                                                                 lstm_1[3][1]                     \n",
      "                                                                 lstm_1[4][1]                     \n",
      "                                                                 lstm_1[5][1]                     \n",
      "                                                                 lstm_1[6][1]                     \n",
      "                                                                 lstm_1[7][1]                     \n",
      "                                                                 lstm_1[8][1]                     \n",
      "                                                                 lstm_1[9][1]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 50, 768)      0           bidirectional[0][0]              \n",
      "                                                                 repeat_vector[0][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[1][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[2][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[3][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[4][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[5][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[6][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[7][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[8][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[9][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[10][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 50, 10)       7690        concatenate[0][0]                \n",
      "                                                                 concatenate[1][0]                \n",
      "                                                                 concatenate[2][0]                \n",
      "                                                                 concatenate[3][0]                \n",
      "                                                                 concatenate[4][0]                \n",
      "                                                                 concatenate[5][0]                \n",
      "                                                                 concatenate[6][0]                \n",
      "                                                                 concatenate[7][0]                \n",
      "                                                                 concatenate[8][0]                \n",
      "                                                                 concatenate[9][0]                \n",
      "                                                                 concatenate[10][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 11)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 50, 1)        11          dense[0][0]                      \n",
      "                                                                 dense[1][0]                      \n",
      "                                                                 dense[2][0]                      \n",
      "                                                                 dense[3][0]                      \n",
      "                                                                 dense[4][0]                      \n",
      "                                                                 dense[5][0]                      \n",
      "                                                                 dense[6][0]                      \n",
      "                                                                 dense[7][0]                      \n",
      "                                                                 dense[8][0]                      \n",
      "                                                                 dense[9][0]                      \n",
      "                                                                 dense[10][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 11, 100)      861800      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1, 512)       0           dense_1[0][0]                    \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 dense_1[1][0]                    \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 dense_1[2][0]                    \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 dense_1[3][0]                    \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 dense_1[4][0]                    \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 dense_1[5][0]                    \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 dense_1[6][0]                    \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 dense_1[7][0]                    \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 dense_1[8][0]                    \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 dense_1[9][0]                    \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 dense_1[10][0]                   \n",
      "                                                                 bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1, 100)       0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 612)       0           dot[0][0]                        \n",
      "                                                                 lambda[0][0]                     \n",
      "                                                                 dot[1][0]                        \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 dot[2][0]                        \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 dot[3][0]                        \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 dot[4][0]                        \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 dot[5][0]                        \n",
      "                                                                 lambda_5[0][0]                   \n",
      "                                                                 dot[6][0]                        \n",
      "                                                                 lambda_6[0][0]                   \n",
      "                                                                 dot[7][0]                        \n",
      "                                                                 lambda_7[0][0]                   \n",
      "                                                                 dot[8][0]                        \n",
      "                                                                 lambda_8[0][0]                   \n",
      "                                                                 dot[9][0]                        \n",
      "                                                                 lambda_9[0][0]                   \n",
      "                                                                 dot[10][0]                       \n",
      "                                                                 lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 256), (None, 889856      concatenate_1[0][0]              \n",
      "                                                                 s0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 concatenate_1[1][0]              \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "                                                                 concatenate_1[2][0]              \n",
      "                                                                 lstm_1[1][1]                     \n",
      "                                                                 lstm_1[1][2]                     \n",
      "                                                                 concatenate_1[3][0]              \n",
      "                                                                 lstm_1[2][1]                     \n",
      "                                                                 lstm_1[2][2]                     \n",
      "                                                                 concatenate_1[4][0]              \n",
      "                                                                 lstm_1[3][1]                     \n",
      "                                                                 lstm_1[3][2]                     \n",
      "                                                                 concatenate_1[5][0]              \n",
      "                                                                 lstm_1[4][1]                     \n",
      "                                                                 lstm_1[4][2]                     \n",
      "                                                                 concatenate_1[6][0]              \n",
      "                                                                 lstm_1[5][1]                     \n",
      "                                                                 lstm_1[5][2]                     \n",
      "                                                                 concatenate_1[7][0]              \n",
      "                                                                 lstm_1[6][1]                     \n",
      "                                                                 lstm_1[6][2]                     \n",
      "                                                                 concatenate_1[8][0]              \n",
      "                                                                 lstm_1[7][1]                     \n",
      "                                                                 lstm_1[7][2]                     \n",
      "                                                                 concatenate_1[9][0]              \n",
      "                                                                 lstm_1[8][1]                     \n",
      "                                                                 lstm_1[8][2]                     \n",
      "                                                                 concatenate_1[10][0]             \n",
      "                                                                 lstm_1[9][1]                     \n",
      "                                                                 lstm_1[9][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 100)       0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1, 100)       0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1, 100)       0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1, 100)       0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1, 100)       0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1, 100)       0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1, 100)       0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1, 100)       0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1, 100)       0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1, 100)       0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8618)         2214826     lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[8][0]                     \n",
      "                                                                 lstm_1[9][0]                     \n",
      "                                                                 lstm_1[10][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 11, 8618)     0           dense_2[0][0]                    \n",
      "                                                                 dense_2[1][0]                    \n",
      "                                                                 dense_2[2][0]                    \n",
      "                                                                 dense_2[3][0]                    \n",
      "                                                                 dense_2[4][0]                    \n",
      "                                                                 dense_2[5][0]                    \n",
      "                                                                 dense_2[6][0]                    \n",
      "                                                                 dense_2[7][0]                    \n",
      "                                                                 dense_2[8][0]                    \n",
      "                                                                 dense_2[9][0]                    \n",
      "                                                                 dense_2[10][0]                   \n",
      "==================================================================================================\n",
      "Total params: 7,309,519\n",
      "Trainable params: 7,309,519\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mVxdfRW_2PMR"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='loss', mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2587410,
     "status": "ok",
     "timestamp": 1585320741270,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "HrJ96DVh2PMZ",
    "outputId": "09f39b1e-5a93-4c93-b109-f3b3c24c9b82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'z = np.zeros((len(encoder_inputs), LATENT_DIM)) # initial [s, c]\\nr = model.fit(\\n  [encoder_inputs, decoder_inputs, z, z], decoder_targets_onehot,\\n  batch_size=BATCH_SIZE,\\n  epochs=20,\\n  callbacks=[es]\\n)'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"z = np.zeros((len(encoder_inputs), LATENT_DIM)) # initial [s, c]\n",
    "r = model.fit(\n",
    "  [encoder_inputs, decoder_inputs, z, z], decoder_targets_onehot,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  epochs=20,\n",
    "  callbacks=[es]\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WIk3E4bC2PMd"
   },
   "outputs": [],
   "source": [
    " model.load_weights(\"./new_weights1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6rtSKw392PMh"
   },
   "source": [
    "# MODEl FOR PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lWCaBOYO2PMj"
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs_placeholder, encoder_outputs)\n",
    "\n",
    "encoder_outputs_as_input = Input(shape=(max_len_input, LATENT_DIM * 2,))\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
    "\n",
    "\n",
    "context = one_step_attention(encoder_outputs_as_input, initial_s)\n",
    "decoder_lstm_input = context_last_word_concat_layer([context, decoder_inputs_single_x])\n",
    "\n",
    "\n",
    "o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[initial_s, initial_c])\n",
    "decoder_outputs = decoder_dense(o)\n",
    "\n",
    "decoder_model = Model(\n",
    "  inputs=[\n",
    "    decoder_inputs_single,\n",
    "    encoder_outputs_as_input,\n",
    "    initial_s, \n",
    "    initial_c\n",
    "  ],\n",
    "  outputs=[decoder_outputs, s, c]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gx41nr822PMp"
   },
   "outputs": [],
   "source": [
    "idx2word_eng = {v:k for k, v in word2idx_input.items()}\n",
    "idx2word_trans = {v:k for k, v in word2idx_output.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ugoy6YEu2PMx"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    \n",
    "    enc_out = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1))\n",
    "\n",
    "    target_seq[0, 0] = word2idx_output['sos']\n",
    "\n",
    "    \n",
    "    eos = word2idx_output['eos']\n",
    "\n",
    "    s = np.zeros((1, LATENT_DIM))\n",
    "    c = np.zeros((1, LATENT_DIM))\n",
    "\n",
    "    output_sentence = []\n",
    "    for _ in range(max_len_target):\n",
    "        o, s, c = decoder_model.predict([target_seq, enc_out, s, c])\n",
    "        idx = np.argmax(o.flatten())\n",
    "\n",
    "        # End sentence of EOS\n",
    "        if eos == idx:\n",
    "            break\n",
    "\n",
    "        word = ''\n",
    "        if idx > 0:\n",
    "            word = idx2word_trans[idx]\n",
    "            output_sentence.append(word)\n",
    "\n",
    "        # Update the decoder input\n",
    "        # which is just the word just generated\n",
    "        target_seq[0, 0] = idx\n",
    "\n",
    "    return ' '.join(output_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2347636,
     "status": "ok",
     "timestamp": 1585323151341,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "ZJvO-RLs2PM1",
    "outputId": "fc7f52d3-7348-4381-ec6c-da9f8410d8df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input: bags seem work well feel sturdy quality materials reviewers commented work measure milk need know much putting ahead time easy adjust far used freeze milk defrosted yet\n",
      "Translation: very good product\n",
      "Original: very good product<eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: ordered food tues received next day supplier thank great expeditious customer service\n",
      "Translation: pinnacle trout sweet\n",
      "Original: pinnacle trout sweet<eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: live new orleans known deliciour pralines coconut pralines bought kelly second time month best ever fresh right size could eaten one day rationed one day intend buy\n",
      "Translation: best pralines ever\n",
      "Original: best pralines ever<eos>\n",
      "Continue? [Y/n]n\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Do some test translations\n",
    "    i = np.random.choice(len(input_texts_1))\n",
    "    input_seq = encoder_inputs[i:i+1]\n",
    "    translation_a = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input:', input_texts_1[i])\n",
    "    print('Translation:', translation_a)\n",
    "    print('Original:',target_texts_1[i])\n",
    "\n",
    "    ans = input(\"Continue? [Y/n]\")\n",
    "    if ans and ans.lower().startswith('n'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qETCY_mw2PM9"
   },
   "outputs": [],
   "source": [
    "n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Untitled.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
